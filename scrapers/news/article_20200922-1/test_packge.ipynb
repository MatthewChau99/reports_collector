{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import config\n",
    "import public_fun\n",
    "def handle(search_word, page, s_date):\n",
    "    url = 'https://api.quzili.cn/search2?tags={}&title=title&skip={}&size=50&time=99999&minpagenum=0&maxpagenum=99999'.format(search_word, page*50)\n",
    "    # index_url2 = 'http://www.bailuzhiku.com{}'\n",
    "    headers = {\n",
    "        'Authorization': 'hmac id=\"AKIDdlutrcn7F4j62Fskwqbiqrki3q3j40r1vjjw\", algorithm=\"hmac-sha1\", headers=\"x-date\", signature=\"BmEXoJSvY8trUMj3BDcqiYo+KhE=\"',\n",
    "        'X-Date': 'Tue, 29 Sep 2020 07:00:50 GMT',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36',\n",
    "    }\n",
    "    res = requests.get(url=url, headers=headers)\n",
    "    res.encoding = res.apparent_encoding\n",
    "    data = json.loads(res.text)\n",
    "    print(data)\n",
    "    result = []\n",
    "    if data['hits']:\n",
    "        pages = page+1 if data['hist']['total'] > page*50 else 0\n",
    "        for d in data['hits']['hits']:\n",
    "            if public_fun.calc_date(s_date=s_date, e_date=d['_source']['time']):\n",
    "                result.append(d['uuid'])\n",
    "        return result, pages\n",
    "    else:\n",
    "        print('url1 404错误:', res.status_code, url)\n",
    "        return [],0\n",
    "\n",
    "def get_data(url, search_word, max_text):\n",
    "    json_result = {'source': 'blzk', 'doc_id': '', 'date': '', 'download_url': '',\n",
    "                   'org_name': '', 'page_num': '1', 'doc_type': 'NEW', 'title': ''}\n",
    "    path = os.path.join(config.SAVE_PATH, search_word, 'news', 'bailuzhiku')\n",
    "    res = requests.get(url=url, headers=config.HEADERS)\n",
    "    html = etree.HTML(res.text)\n",
    "    content_text = public_fun.filter_space_json(html.xpath('//*[@class=\"textarea-box policy-textarea\"]//text()'))\n",
    "    if len(content_text) > max_text:\n",
    "        try:\n",
    "            doc_id = url.split('/')[-1].replace('.html', '') # 文章ID\n",
    "            title = html.xpath('//*[@class=\"policy-wrap-title\"]/h1')[0]   #文章标题\n",
    "            # author = html.xpath('//*[@class=\"left-details-head\"]')[0]\n",
    "            # summary = html.xpath('//*[@class=\"summary\"]')[0]\n",
    "            description = html.xpath('//*[@class=\"textarea-box policy-textarea\"]')[0]   #文章内容\n",
    "            html_list = [title, description]\n",
    "            html_result = public_fun.filter_space_html(html_list)\n",
    "            json_result['doc_id'] = doc_id\n",
    "            json_result['date'] = public_fun.filter_space_json(html.xpath('//*[@class=\"attribute-table\"]/tbody/tr[2]/td[1]/div/text()')[0]\n",
    "                                                               .replace('-', ''))\n",
    "            json_result['download_url'] = 'http://www.bailuzhiku.com/'+html.xpath('//*[@class=\"header-tool-link download\"]/@href')[0]\n",
    "            try:\n",
    "                json_result['org_name'] = public_fun.filter_space_json(html.xpath('//*[@class=\"attribute-table\"]/tbody/tr[1]/td[1]/div/text()')[0])\n",
    "            except:\n",
    "                json_result['org_name'] = ''\n",
    "            json_result['title'] = public_fun.filter_space_json(html.xpath('//h1[@class=\"title\"]/text()')[0])\n",
    "            public_fun.write_down_json(path=path, filename=doc_id + '.json', text=json_result)\n",
    "            public_fun.write_down_html(path=path, filename=doc_id + '.html', text=html_result)\n",
    "        except Exception as e:\n",
    "            print(e.__traceback__.tb_lineno, url, e)\n",
    "    else:\n",
    "        print('文章字数不足', max_text)\n",
    "\n",
    "def main(search_word, max_art, max_text, s_date):\n",
    "    '''\n",
    "    铅笔道爬虫入口函数\n",
    "    :param search_word:搜索关键词 \n",
    "    :return: None\n",
    "    '''\n",
    "    page = 1\n",
    "    url2_list = []\n",
    "    while page:\n",
    "        one_page_url,pages = handle(search_word=search_word, page=page, s_date=s_date)\n",
    "        url2_list += one_page_url\n",
    "        if len(url2_list) < max_art and page < int(pages):\n",
    "            page += 1\n",
    "        else:\n",
    "            page = 0\n",
    "    return url2_list\n",
    "    # url2_list = url2_list[:5] if config.DEBUG else url2_list\n",
    "    # for url2 in url2_list:\n",
    "    #     get_data(url=url2, search_word=search_word, max_text=max_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'message': 'HMAC signature cannot be verified, the x-date header is out of date for HMAC Authentication'}\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-46e5b484ca48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mp3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2018-01-01'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_art\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-8ddf6b4a27d8>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(search_word, max_art, max_text, s_date)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0murl2_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mone_page_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0murl2_list\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mone_page_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl2_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_art\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-8ddf6b4a27d8>\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(search_word, page, s_date)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mpages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hits'"
     ],
     "ename": "KeyError",
     "evalue": "'hits'",
     "output_type": "error"
    }
   ],
   "source": [
    "p0 = '人工智能'\n",
    "p1 = 100\n",
    "p2 = 500\n",
    "p3 = '2018-01-01'\n",
    "r2 = main(search_word=p0, max_art=p1, max_text=p2, s_date=p3)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{\"status\":500,\"message\":\"参数解析异常\"}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "# 请求测试部分\n",
    "test_url = 'https://www.1c9u.com/prod-api/api/1c9u/documentInfo/list'\n",
    "headers = {\n",
    "    'Cookie': 'sidebarStatus=0',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36',\n",
    "}\n",
    "form_data = json.loads('{\"searchType\":\"word\",\"word\":\"人工智能\",\"recommend\":\"\",\"fileType\":\"\",\"type\":\"DOCUMENT\",\"tag\":\"\",\"useWildcard\":1,\"page\":{\"current\":1,\"size\":10,\"ascs\":[],\"descs\":[],\"sort\":\"+id\"}}')\n",
    "test_res = requests.post(url=test_url, headers=headers, data=form_data)\n",
    "test_res.encoding = test_res.apparent_encoding\n",
    "print(test_res.text)\n",
    "data = json.loads(test_res.text)\n",
    "# test_string = '云南省人民政府关于印'\n",
    "# print(test_string in test_res.text)\n",
    "# with open('test_check', 'w', encoding='utf-8') as f:\n",
    "#     f.write(test_res.text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 其他测试部分\n",
    "# a = '{\"searchType\":\"word\",\"word\":\"人工智能\",\"recommend\":\"\",\"fileType\":\"\",\"type\":\"DOCUMENT\",\"tag\":\"\",\"useWildcard\":1,\"page\":{\"current\":1,\"size\":10,\"ascs\":[],\"descs\":[],\"sort\":\"+id\"}}'\n",
    "# b = json.loads(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}